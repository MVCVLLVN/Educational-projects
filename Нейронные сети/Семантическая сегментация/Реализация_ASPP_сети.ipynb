{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAW-KZShLpio"
      },
      "source": [
        "# Реализация ASPP сети\n",
        "В этом уроке мы создадим еще еще одну сегментационную FCN модель на основе блока ASPP (Atrous Spatial Pyramid Pooling), который основан на дилатационных свёртках (Atrous Conv, Dilated Conv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByrUHJULLpiq"
      },
      "source": [
        "### Загрузка необходимых библиотек\n",
        "Здесь мы загружаем различне библиотеки, включая TensoFlow.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaMg5neBLpir",
        "outputId": "e614ac8c-b9de-4a71-cac3-6aa65a4eeff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.15.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "print('TensorFlow version:', tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z-lR4n8Lpjc"
      },
      "source": [
        "### Создание ASPP модели\n",
        "В этом примере мы будем создавать модель `ASPPNet` через собственный класс, наследованный от `tf.keras.Model`. Кроме того, будем использовать возможность модульного создания нейросетей. Сначала создадим отдельно модель для ASPP блока (блок, который содержит только дилатационные свёртки и применяется между энкодером и декодером), которая по сути будет являться самостоятельным слоем. А затем создадим финальную модель `ASPPNet`, в который `ASPPBlock` будет использоваться как слой между Энкодером и Декодером.\n",
        "\n",
        "В ASPP блоке (`ASPPBlock`) ко входному тензору параллельно применяются обычная свёртка 1x1 и несколько дилатационных свёрток. Затем все эти резульаты конкатенируются. Далее \"перемешиваем\" каналы полученного тензора с помощью еще одной свёртки 1x1.\n",
        "\n",
        "В финальной ASPP модели (`ASPPNet`) в качестве Энкодера будем использовать стандартные свёртки и пулинги. Далее в боттлнеке (в середине сети) применим слой ASPPBlock. А в Декодере будем использовать более простую архитектуру: меньше свёрток, повышение размерности с помощью двух билинейных интерполяций (`tf.image.resize`). Кроме того, в сети присутствуют две проброшенные связи."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xRU14xxDLpje"
      },
      "outputs": [],
      "source": [
        "class ASPPBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "\n",
        "    def call(self, inp, is_training=False):\n",
        "        out1 = self.conv1(inp)\n",
        "        out2 = self.conv2(inp)\n",
        "        out3 = self.conv3(inp)\n",
        "        out4 = self.conv4(inp)\n",
        "        out = tf.concat([out1, out2, out3, out4], axis=3)\n",
        "        out = self.conv5(out)\n",
        "        return out\n",
        "\n",
        "class ASPPNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv7 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv8 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv9 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv10 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "\n",
        "        self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')\n",
        "        self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)\n",
        "\n",
        "        self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\n",
        "        self.aspp = ASPPBlock()\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "        out_enc_mid = out\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv7(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv9(out)\n",
        "        out = self.conv10(out)\n",
        "\n",
        "        out = self.aspp(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(out_enc_mid)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "\n",
        "        out_enc_mid = self.conv11(out_enc_mid)\n",
        "\n",
        "        out = tf.concat([out, out_enc_mid], axis=3)\n",
        "\n",
        "        out = self.conv12(out)\n",
        "        out = self.conv13(out)\n",
        "        out = self.conv14(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "        out = tf.nn.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "model = ASPPNet()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duIuW1HVhZXU"
      },
      "source": [
        "### Задания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg5VqQGEgiq5"
      },
      "source": [
        "\n",
        "**[ЗАДАНИЕ 1]** Вопрос: почему в ASPPNet в первой билинейной интерполяции (`tf.image.resize`) в качестве желаемого выходного размера тензора мы используем размер тензора `out_enc_mid`?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "В модели ASPPNet используется первая билинейная интерполяция с размером тензора out_enc_mid по следующим причинам:\n",
        "\n",
        "Восстановление пространственного разрешения:\n",
        "В первой билинейной интерполяции происходит увеличение разрешения выходного тензора после блока ASPP до размера, совпадающего с разрешением промежуточного выхода out_enc_mid. Это необходимо для корректного объединения информации из разных уровней (skip connections).\n",
        "\n",
        "Skip connections:\n",
        "Архитектура модели предполагает использование skip connections для соединения информации из предыдущих уровней свёрточных слоёв (encoder) с последующими уровнями (decoder). Такие соединения позволяют объединить контекстную информацию из более глубоких слоёв с более детальной информацией из поверхностных слоёв, что улучшает сегментационные возможности модели.\n",
        "\n",
        "Слияние признаков:\n",
        "Для эффективного объединения информации из разных уровней модели важно, чтобы тензоры, которые объединяются через слой Concatenate, имели одинаковое разрешение. Таким образом, выходной тензор после блока ASPP интерполируется до разрешения out_enc_mid, что позволяет корректно объединить его с out_enc_mid в следующем шаге.\n",
        "\n",
        "Обоснование\n",
        "ASPP блок:\n",
        "Обрабатывает тензор для извлечения контекстной информации с использованием различных уровней дилатации (dilation rates). После этого необходимо вернуть пространственное разрешение тензора обратно для дальнейшего объединения с признаками из out_enc_mid.\n",
        "\n",
        "Объединение признаков:\n",
        "После билинейной интерполяции до разрешения out_enc_mid, выход блока ASPP объединяется с этим промежуточным выходом. Это помогает модели лучше восстанавливать детали в процессе декодирования."
      ],
      "metadata": {
        "id": "8SsOok7rxtXf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA36-I0mh5yc"
      },
      "source": [
        "\n",
        "**[ЗАДАНИЕ 2]** Реализуйте пайплайн обучения для модели ASPPNet: подготовка данных, лосс, обучение, тестирование. Используйте материалы из предыдущего практического урока. Обучите модель и сравните время обучения с временем обучения более простых версий FCN из предыдущих уроков."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "# Функция для загрузки и предобработки данных\n",
        "def load_data(image_paths, mask_paths, img_size):\n",
        "    images = [tf.image.resize(tf.image.decode_png(tf.io.read_file(img_path), channels=3), img_size) / 255.0 for img_path in image_paths]\n",
        "    masks = [tf.image.resize(tf.image.decode_png(tf.io.read_file(mask_path), channels=1), img_size) / 255.0 for mask_path in mask_paths]\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "# Загрузка данных (пример с путями к данным)\n",
        "image_paths = ['path/to/images/1.png', 'path/to/images/2.png', ...]\n",
        "mask_paths = ['path/to/masks/1.png', 'path/to/masks/2.png', ...]\n",
        "img_size = (256, 256)\n",
        "\n",
        "images, masks = load_data(image_paths, mask_paths, img_size)\n",
        "x_train, x_val, y_train, y_val = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    smooth = 1e-7\n",
        "    y_true_f = tf.keras.backend.flatten(y_true)\n",
        "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
        "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1 - dice_coefficient(y_true, y_pred)\n",
        "\n",
        "\n",
        "class ASPPBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "\n",
        "    def call(self, inp, is_training=False):\n",
        "        out1 = self.conv1(inp)\n",
        "        out2 = self.conv2(inp)\n",
        "        out3 = self.conv3(inp)\n",
        "        out4 = self.conv4(inp)\n",
        "        out = tf.concat([out1, out2, out3, out4], axis=3)\n",
        "        out = self.conv5(out)\n",
        "        return out\n",
        "\n",
        "class ASPPNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv7 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv8 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv9 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv10 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "\n",
        "        self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')\n",
        "        self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)\n",
        "\n",
        "        self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\n",
        "        self.aspp = ASPPBlock()\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "        out_enc_mid = out\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv7(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv9(out)\n",
        "        out = self.conv10(out)\n",
        "\n",
        "        out = self.aspp(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(out_enc_mid)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "\n",
        "        out_enc_mid = self.conv11(out_enc_mid)\n",
        "\n",
        "        out = tf.concat([out, out_enc_mid], axis=3)\n",
        "\n",
        "        out = self.conv12(out)\n",
        "        out = self.conv13(out)\n",
        "        out = self.conv14(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "        out = tf.nn.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "model = ASPPNet()\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam', loss=dice_loss, metrics=[dice_coefficient])\n",
        "\n",
        "# Настройка для замера времени обучения\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    epochs=50,\n",
        "                    batch_size=16)\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "print(f'Training time: {training_time} seconds')\n",
        "\n",
        "\n",
        "loss, dice = model.evaluate(x_val, y_val)\n",
        "print(f'Validation Loss: {loss}')\n",
        "print(f'Validation Dice Coefficient: {dice}')\n"
      ],
      "metadata": {
        "id": "KWpl2vbSxban"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_predictions(model, x_val, y_val):\n",
        "    predictions = model.predict(x_val)\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    for i in range(5):\n",
        "        plt.subplot(3, 5, i + 1)\n",
        "        plt.imshow(x_val[i])\n",
        "        plt.title('Input Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(3, 5, i + 6)\n",
        "        plt.imshow(y_val[i].squeeze(), cmap='gray')\n",
        "        plt.title('True Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(3, 5, i + 11)\n",
        "        plt.imshow(predictions[i].squeeze(), cmap='gray')\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, x_val, y_val)\n"
      ],
      "metadata": {
        "id": "RTqJz-1XyMGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример для обучения простой модели FCN\n",
        "def build_simple_fcn_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 3)),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPooling2D((2,\n"
      ],
      "metadata": {
        "id": "pA722f2oyOtH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}